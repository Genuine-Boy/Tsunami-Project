{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Big Wave\n",
    "Progect Leads: Trevor McLean, Avery Meyers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be doing a case study excersise in simplifying and visually representing the progression and creation of three tsunamis through\n",
    "an analysis of the water level data from several stations. We will be creating a map with the three epicenters and locations of stations \n",
    "from which the data was obtained, as well as radius rings from the epicenters of amplitude at distance. As well we have a bar graph of \n",
    "the high points of amplitude for all three tsunamis against one another for the first 30 min range after start. And lastly we will have \n",
    "graphs of general data about the water level caused by the tsunamis obtained from the stations. (We may have a dedicated graph for\n",
    "representing amplitude over time for all three tsunamis together to highlight patterns.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data of water level from three stations per tsunami will be necessary, as well as general history and general statistics about the tsunamis and their effects. The only resultant data would be a progression of amplitude form epicenter for each tsunami."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy, matplotlib, datetime, and mpl_toolkits.basemap modules will be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expect the project will take about 20 man-hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from netCDF4 import Dataset, date2index\n",
    "import math\n",
    "\n",
    "\n",
    "def read_data(f_name):\n",
    "    '''(str) -> (list, list)\n",
    "    \n",
    "    Takes in a file of primary water levels against time and parses the data into\n",
    "    two lists: a list of times and a list of primary water level(pwl). Returns those\n",
    "    lists in a tuple.\n",
    "    '''\n",
    "    with open(f_name, 'r') as f_temp:\n",
    "        f_temp.readline()\n",
    "        f_temp.readline()\n",
    "        L_time = []\n",
    "        L_pwl = []\n",
    "        \n",
    "        for i in f_temp:\n",
    "            L_temp = i.strip().split('\\t')\n",
    "            L_time.append(L_temp[0])\n",
    "            L_pwl.append(float(L_temp[1]))\n",
    "                         \n",
    "    return L_time, L_pwl\n",
    "\n",
    "\n",
    "def read_lat_lon(name):\n",
    "    with open(name, 'r') as f:\n",
    "        f.readline()\n",
    "        stations = {}\n",
    "        for l in f:\n",
    "            temp_l = l.strip().split(',')\n",
    "            stations[temp_l[0]] = (float(temp_l[1]), float(temp_l[2]))\n",
    "        return stations\n",
    "            \n",
    "\n",
    "                         \n",
    "def data_point_time(L_time):\n",
    "    '''(list) -> list\n",
    "    \n",
    "    Takes in a list of times L_times in the formal of files from the IOC and reduces it down\n",
    "    to a series of integers representative of the amount of minutes that have passed at any \n",
    "    given point. Returns a list of equal length that contains float quantities of minutes \n",
    "    passed.\n",
    "    \n",
    "    >>> data_point_time(['2011-03-11 00:05:00', '2011-03-11 01:23:00'])\n",
    "    [5, 83]\n",
    "    >>> data_point_time(['2011-03-11 00:00:00', '2011-03-11 01:23:00', '2011-03-11 01:23:00', '2011-03-11 01:23:00'])\n",
    "    [0, 83, 83, 83]\n",
    "    '''\n",
    "    \n",
    "    L_time_initial = L_time[0]\n",
    "    format_time = L_time_initial.split()\n",
    "    format_time_list = format_time[0].split('-') + format_time[1].split(':')\n",
    "    base_time = dt.datetime(year=int(format_time_list[0]),\n",
    "                            month=int(format_time_list[1]),\n",
    "                            day=int(format_time_list[2]), \n",
    "                            hour=int(format_time_list[3]), \n",
    "                            minute=int(format_time_list[4])\n",
    "                           )\n",
    "    \n",
    "    L_time_minutes = []\n",
    "    for time in L_time:\n",
    "        temp_time = time.split()\n",
    "        temp_time_list = temp_time[0].split('-') + temp_time[1].split(':')\n",
    "        current_time = dt.datetime(year=int(temp_time_list[0]),\n",
    "                                    month=int(temp_time_list[1]),\n",
    "                                    day=int(temp_time_list[2]), \n",
    "                                    hour=int(temp_time_list[3]), \n",
    "                                    minute=int(temp_time_list[4])\n",
    "                                   )\n",
    "        time_difference = (current_time - base_time).total_seconds() / 60\n",
    "        L_time_minutes.append(time_difference)\n",
    "        \n",
    "    return L_time_minutes\n",
    "\n",
    "def calculate_amplitudes(L_time, L_pwl):\n",
    "    '''(list, list) -> dict\n",
    "    \n",
    "    Takes in a list of times L_time and a list of precision water levels L_pwl and calculates\n",
    "    a right-side amplitude approximation for every wave of the plot. Returns those amplitudes\n",
    "    as values paired with a key of the time of the peak for each amplitude in a dictionary.\n",
    "    '''\n",
    "    \n",
    "    start = 0\n",
    "    end = 0\n",
    "    amplitudes = {}\n",
    "    for i in range(1, len(L_pwl)):\n",
    "        if (len(L_pwl) - 1) == i:\n",
    "            break\n",
    "            \n",
    "        if L_pwl[i] < L_pwl[i+1] and L_pwl[i-1] >= L_pwl[i]:\n",
    "            start = L_pwl[i]\n",
    "        elif L_pwl[i] > L_pwl[i+1] and L_pwl[i-1] <= L_pwl[i]:\n",
    "            end = L_pwl[i]\n",
    "            peak = i\n",
    "            \n",
    "        if start and end:\n",
    "            amplitudes[L_time[peak]] = 100 * round(((abs(end) - abs(start)) / 2), 4)\n",
    "            start = 0\n",
    "            end = 0\n",
    "            \n",
    "    return amplitudes\n",
    "\n",
    "def find_start(time_list, pwl_list):\n",
    "    '''\n",
    "    (list, list) -> num\n",
    "\n",
    "    Takes in a list of times and percision water levels and returns an index on the x axis where \n",
    "    the start of a tsunami event can be graphed.\n",
    "\n",
    "    '''\n",
    "    running_avg = 0\n",
    "    last_total = 0\n",
    "    for i in range(1, len(pwl_list)):\n",
    "        diff = abs(pwl_list[i] - pwl_list[i-1])\n",
    "        if i > 30:\n",
    "            if diff > running_avg*6.3:\n",
    "                return time_list[i]\n",
    "            else:\n",
    "                last_total = last_total + diff\n",
    "                running_avg = last_total/i\n",
    "        else: \n",
    "            last_total = last_total + diff\n",
    "            running_avg = last_total/i\n",
    "    return None\n",
    "\n",
    "def determine_max(sub_dict):\n",
    "    '''(dict) -> float\n",
    "    \n",
    "    '''\n",
    "    amps = sub_dict['amps']\n",
    "    ctr = 0\n",
    "    for time in amps:\n",
    "        if amps[time] > ctr:\n",
    "            ctr = amps[time]\n",
    "    #if time <= sub_dict['start'] + 30:\n",
    "            \n",
    "    return ctr\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "def find_distance(epilat, epilon, stations):\n",
    "    \n",
    "    #In Kilometers\n",
    "    R = 6373.0\n",
    "\n",
    "    lat1 = math.radians(epilat)\n",
    "    lon1 = math.radians(epilon)\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    for station in stations:\n",
    "        lat2 = math.radians(station[0])\n",
    "        lon2 = math.radians(station[1])\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "\n",
    "        #Haversine formula\n",
    "        a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "        distance = R * c\n",
    "        distances.append(distance)\n",
    "    return distances\n",
    "\n",
    "def find_distance2(epilat, epilon, stations):\n",
    "    \n",
    "    #In Kilometers\n",
    "    R = 6373.0\n",
    "\n",
    "    lat1 = math.radians(epilat)\n",
    "    lon1 = math.radians(epilon)\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    for station in stations:\n",
    "        lat2 = math.radians(station[0])\n",
    "        lon2 = math.radians(station[1])\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "\n",
    "        #Haversine formula\n",
    "        a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "        distance = R * c\n",
    "        distances.append(distance)\n",
    "    return distances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info gathered from(primarily) USGS.gov and sms-tsunami-warning.com\n",
    "#### Data gathered from ioc-sealevelmonitoring.org\n",
    "\n",
    "Tsunamis are large waves caused primarily by earthquakes or other phenomenons of ocean water shifting such as from coastal land-slides and techtonic shifts. \n",
    "The term tsunami was adapted from japanese at around world war 2. 'Tsu' meaning harbor and 'Nami' meaning wave.\n",
    "\n",
    "##### Japan 2011, Miyagi Prefecture Tsunami: Caused by a 9.0 magnitude undersea earthquake on March 11 \n",
    "##### Chile 2010, Maule: Caused by a 8.8 magnitude earthquake on February 27 \n",
    "##### Solomon Islands, Lata 2013: Caused by a 8.0 magnitude earthquake on February 06 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variation(info_structure, station_name, color):\n",
    "    '''(list(lists), list(lists)) -> None\n",
    "    \n",
    "    Graphs a representation of the water level change over time for multiple different sets of data. \n",
    "    Takes in two lists of lists where each internal list of the list time_lists is the times of data collection\n",
    "    converted to minutes by the function data_point_time. The list pwl_lists contains lists of precision water level\n",
    "    associated with the respective index of list of time points. This function returns none and prints all given \n",
    "    pairs of time and pwl lists. There must be equal amounts of lists in time_lists and pwl_lists. As well, those\n",
    "    lists must be of equal length.\n",
    "    '''\n",
    "    # FIXME (docstring)\n",
    "    \n",
    "    plt.figure()\n",
    "    times = info_structure[station_name]['times']\n",
    "    pwls = info_structure[station_name]['pwls']\n",
    "    plt.plot(times, pwls, color + '--') \n",
    "    plt.axvline(find_start(times, pwls))\n",
    "    plt.title(info_structure['name'] + ', ' + station_name)\n",
    "    plt.xlabel('Minutes')\n",
    "    plt.ylabel('Percision Water Level(PWL)')\n",
    "    \n",
    " \n",
    "def plot_amp_max_per_tsunami(info_structures, L_color_code):\n",
    "    '''(list, list) -> None\n",
    "    \n",
    "    '''\n",
    "   \n",
    "    plt.figure()\n",
    "    plt.xlabel('Station')\n",
    "    plt.ylabel('Amplitude(Centimeters)')\n",
    "    ctr = 0\n",
    "    for tsunami in info_structures:\n",
    "        max_amps = []\n",
    "        for station in tsunami['station_names']:\n",
    "            max_amps.append(tsunami[station]['max_amp'])\n",
    "        plt.bar(tsunami['station_names'], max_amps, label = tsunami['name'], color = L_color_code[ctr])\n",
    "        ctr += 1\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    " \n",
    "def hell(info_structures):\n",
    "    '''(list) -> None\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0.05, 0.05, 0.9, 0.9])\n",
    "    m = Basemap(projection = 'merc', llcrnrlat = -80, urcrnrlat = 80, llcrnrlon = -180, urcrnrlon = 180, lat_ts = 20, resolution = 'c', lat_0=20, lon_0=-170)\n",
    "    #, llcrnrlat = -80, urcrnrlat = 80, llcrnrlon = -180, urcrnrlon = 180, lat_ts = 20, resolution = 'c'\n",
    "    \n",
    "    m.drawcoastlines()\n",
    "    m.drawmapboundary(fill_color = 'aqua')\n",
    "    #m.fillcontinents(color = 'black')\n",
    "    \n",
    "    \n",
    "    colors1= ['b', 'g', 'r']\n",
    "    colors2= ['darkblue', 'darkgreen', 'darkred']\n",
    "    for tsunami in info_structures:\n",
    "        lats = []\n",
    "        lons = []\n",
    "        for station in tsunami['station_names']:\n",
    "            lons.append(tsunami[station]['lat_lon'][1])\n",
    "            lats.append(tsunami[station]['lat_lon'][0])\n",
    "            \n",
    "        x, y = m(lons, lats)\n",
    "        m.scatter(x, y, marker='D', color=colors1.pop())\n",
    "        \n",
    "        x2, y2 = m(tsunami['tsu_lat_lon'][1], tsunami['tsu_lat_lon'][0])\n",
    "        m.plot(x2, y2, marker='D', color=colors2.pop(), markersize=10)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def plot_amplitude(amps1, name, c):\n",
    "\n",
    "    t1 = []\n",
    "    a1 = []\n",
    "\n",
    "    for time in amps1:\n",
    "        t1.append(time)\n",
    "        a1.append(amps1[time])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(t1, a1, color = c, s = 1)\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Minutes')\n",
    "    plt.ylabel('Amplitude in cm')\n",
    "    \n",
    "\n",
    "def plot_amps_distances(dictionaries):\n",
    "    color = ['bo--', 'go--', 'ro--']\n",
    "    c_i = 0\n",
    "    plt.figure()\n",
    "    for dictionary in dictionaries:\n",
    "        station_names = dictionary['station_names']\n",
    "        epi_lat_lon = dictionary['tsu_lat_lon']\n",
    "        name = dictionary['name']\n",
    "        \n",
    "        stations_lat_lon = []\n",
    "        max_amps = []\n",
    "        for s in station_names:\n",
    "            max_amps.append(dictionary[s]['max_amp'])\n",
    "            stations_lat_lon.append(dictionary[s]['lat_lon'])\n",
    "\n",
    "        distances = find_distance(epi_lat_lon[0], epi_lat_lon[1], stations_lat_lon)\n",
    "        plt.plot(distances, max_amps, color[c_i])\n",
    "        c_i = c_i + 1\n",
    "    plt.title('Max Wave Amplitude vs Distance')\n",
    "    plt.xlabel('Distance from Epicenter in Kilometers')\n",
    "    plt.ylabel('Max Amplitude in Centimeters')\n",
    "\n",
    "\n",
    "def info_structure(station_files, lat_lon_file, station_names, tsunami_name):\n",
    "    '''(list, str) -> dict\n",
    "    \n",
    "    '''\n",
    "    super_dict = {}\n",
    "    \n",
    "    latlon_dict = read_lat_lon(lat_lon_file)\n",
    "    \n",
    "    index = 0\n",
    "    for file in station_files:\n",
    "        sub_dict = {}\n",
    "        temp_times, temp_pwls = read_data(file)\n",
    "        sub_dict['long_times'] = temp_times\n",
    "        sub_dict['pwls'] = temp_pwls\n",
    "        sub_dict['times'] = data_point_time(temp_times)\n",
    "        sub_dict['amps'] = calculate_amplitudes(sub_dict['times'], temp_pwls)\n",
    "        sub_dict['start'] = find_start(sub_dict['times'], temp_pwls)\n",
    "        sub_dict['max_amp'] = determine_max(sub_dict)\n",
    "        sub_dict['lat_lon'] = latlon_dict[station_names[index]]\n",
    "        super_dict[station_names[index]] = sub_dict\n",
    "        index += 1\n",
    "        \n",
    "    super_dict['tsu_lat_lon'] = latlon_dict[tsunami_name]\n",
    "    super_dict['station_names'] = station_names\n",
    "    super_dict['name'] = tsunami_name\n",
    "    \n",
    "    return super_dict\n",
    "        \n",
    "\n",
    "def main():\n",
    "\n",
    "    Japan_2011 = info_structure(['Japan(Omaezaki).txt', 'Japan(Honiara).txt', 'Japan(Westport_WA).txt'],\n",
    "                                'Lat_Lon.txt',\n",
    "                                ['Omaezaki', 'Honiara', 'Westport WA'],\n",
    "                                'Japan 2011'\n",
    "                               )\n",
    "\n",
    "    Chile_2010 = info_structure(['Chile(Omaezaki).txt', 'Chile(Antofagasta_CL).txt', 'Chile(San_Felix_CL).txt'],\n",
    "                                'Lat_Lon.txt',\n",
    "                                ['Omaezaki', 'Antofagasta CL', 'San Felix CL'],\n",
    "                                'Chile 2010'\n",
    "                               )\n",
    "\n",
    "    Solomon_2013 = info_structure(['Solomon_Islands(Honiara).txt', 'Solomon_Islands(Lata_Wharf_SB).txt', 'Solomon_Islands(Lautoka_FJ).txt'],\n",
    "                                'Lat_Lon.txt',\n",
    "                                ['Honiara', 'Lata Wharf SB', 'Lautoka FJ'],\n",
    "                                'Solomon Islands 2013'\n",
    "                               )\n",
    "    \n",
    "    tsunamis = [Japan_2011, Chile_2010, Solomon_2013]\n",
    "\n",
    "    hell(tsunamis)\n",
    "    plot_amp_max_per_tsunami(tsunamis, ['b', 'g', 'r'])\n",
    "    \n",
    "    colors= ['b', 'g', 'r']\n",
    "    for i in range(3):\n",
    "        plot_variation(tsunamis[i], tsunamis[i]['station_names'][0], colors[i])\n",
    "    for i in range(3):\n",
    "        plot_variation(tsunamis[i], tsunamis[i]['station_names'][1], colors[i])\n",
    "    for i in range(3):\n",
    "        plot_variation(tsunamis[i], tsunamis[i]['station_names'][2], colors[i])\n",
    "        \n",
    "    #print(Japan_2011['Omaezaki']['amps'])\n",
    "    \n",
    "    plot_amps_distances(tsunamis)\n",
    "    \n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above data displays the original behavior of the wave data. Though the points in time that they began is inconsistant, there is still an interesting similarity between each graph as once the event begins, instead of just causing quite high water levels, it instead causes a fluxuation to really high water levels, then to exceptionally low water levels. This as well seems to be following a general trend of shape of the standard fluctuations of water level. This is likely due to the tsunami fluxuations being an alteration of a consistant change in normal tide, meaning that the tide still follows normal behaviour in spite of the tsunami. I may write a function in future to remove the tide change aspect from the graph so that the specific fluctuations of the tsunami can be isolated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
