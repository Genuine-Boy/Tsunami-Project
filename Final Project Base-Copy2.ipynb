{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Big Wave\n",
    "Progect Leads: Trevor McLean, Avery Meyers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "There are many devastating forces of nature that afflict the artifice of humanity. But few of them are as destructive as the tsunami. In roughly the last 20 years there have been about a quater of a million deaths by tsunamis(WHO) as well as a terrible amount of damage to homes and infrstructure. Though this is only about a third of the deaths of deaths in the same time from earthquakes, this is still no small amount of people, especially when considering that earthquakes tend to be the most deadly natural disaster. So what is one to do about this? Well, as is likely obvious, there is nothing anyone can do to stop tsunamis from occuring, so the best method to protect against them may be to understand them. In the following document, we will be writing rudementary code to display and analyze certain aspects of water level date in order to get a better understanding of the mechanics and behaviour of a tsunami.\n",
    "\n",
    "#### Info gathered from(primarily) USGS.gov, sms-tsunami-warning.com, and World Health Orginization\n",
    "#### Data gathered from ioc-sealevelmonitoring.org\n",
    "\n",
    ".\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    ".\n",
    "\n",
    "### Context\n",
    "\n",
    "Firstly some context. Tsunamis are large waves caused primarily by earthquakes or other phenomenons of ocean water shifting such as from coastal land-slides and techtonic shifts. This causes massive waves that can then travel as far as to other continents until something gets in their way and they break upon the earth, often preceded by a temporary decrease in costal water level as water is pulled under and into the stunami waves that only now grow in height. However some can die out quicker since they may not have the energy necessary to go great distances. For the sake of very accessible and well-documented data, we will be looking at three large tsunamis of the last 15 years with three points of reference data for each. These tsunamis are all originating from earthquakes of a determined magnitude. \n",
    "\n",
    "The data of the tsunamis will be extrapolated from the readings of many water-level observation stations around the world. These stations function off of a tide gauge to measure the tide and any irregularities. There are a few common types of tide gauge like float gauges and staff gauges, but most modern tide gauges use technology like radar or other wave-based tech to obtain their data. Some stations even use multiple types of data collection.\n",
    "\n",
    "The data we collected is for the following tsunamis, specifically over a five-day period for the Japan and Chile tsunamis, though instead over a two-day period for the Solomon Island tsunami due to a relativley smaller effect from the tsunami. The start date and other information about the tsunamis is as follows:\n",
    "\n",
    "##### Japan 2011, Miyagi Prefecture Tsunami: Caused by a 9.0 magnitude undersea earthquake on March 11 \n",
    "##### Chile 2010, Maule: Caused by a 8.8 magnitude earthquake on February 27 \n",
    "##### Solomon Islands, Lata 2013: Caused by a 8.0 magnitude earthquake on February 06 \n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from netCDF4 import Dataset, date2index\n",
    "import math\n",
    "\n",
    "\n",
    "def read_data(f_name):\n",
    "    '''(str) -> (list, list)\n",
    "    \n",
    "    Takes in a file of primary water levels against time and parses the data into\n",
    "    two lists: a list of times and a list of primary water level(pwl). Returns those\n",
    "    lists in a tuple.\n",
    "    '''\n",
    "    with open(f_name, 'r') as f_temp:\n",
    "        f_temp.readline()\n",
    "        f_temp.readline()\n",
    "        L_time = []\n",
    "        L_pwl = []\n",
    "        \n",
    "        for i in f_temp:\n",
    "            L_temp = i.strip().split('\\t')\n",
    "            L_time.append(L_temp[0])\n",
    "            L_pwl.append(float(L_temp[1]))\n",
    "                         \n",
    "    return L_time, L_pwl\n",
    "\n",
    "\n",
    "def read_lat_lon(name):\n",
    "    '''(str) -> dict\n",
    "    \n",
    "    Takes in a file of latitudes and longitudes and puts the data into a tuple\n",
    "    as the value of a key-value pair in a dictionary. The keys are the names \n",
    "    associated to the coordinates. Returns a dictionary of those values.\n",
    "    '''\n",
    "    with open(name, 'r') as f:\n",
    "        f.readline()\n",
    "        stations = {}\n",
    "        for l in f:\n",
    "            temp_l = l.strip().split(',')\n",
    "            stations[temp_l[0]] = (float(temp_l[1]), float(temp_l[2]))\n",
    "        return stations\n",
    "            \n",
    "\n",
    "                         \n",
    "def data_point_time(L_time):\n",
    "    '''(list) -> list\n",
    "    \n",
    "    Takes in a list of times L_times in the formal of files from the IOC and reduces it down\n",
    "    to a series of integers representative of the amount of minutes that have passed at any \n",
    "    given point. Returns a list of equal length that contains float quantities of minutes \n",
    "    passed.\n",
    "    \n",
    "    >>> data_point_time(['2011-03-11 00:05:00', '2011-03-11 01:23:00'])\n",
    "    [5, 83]\n",
    "    >>> data_point_time(['2011-03-11 00:00:00', '2011-03-11 01:23:00', '2011-03-11 01:23:00', '2011-03-11 01:23:00'])\n",
    "    [0, 83, 83, 83]\n",
    "    '''\n",
    "    \n",
    "    L_time_initial = L_time[0]\n",
    "    format_time = L_time_initial.split()\n",
    "    format_time_list = format_time[0].split('-') + format_time[1].split(':')\n",
    "    base_time = dt.datetime(year=int(format_time_list[0]),\n",
    "                            month=int(format_time_list[1]),\n",
    "                            day=int(format_time_list[2]), \n",
    "                            hour=int(format_time_list[3]), \n",
    "                            minute=int(format_time_list[4])\n",
    "                           )\n",
    "    \n",
    "    L_time_minutes = []\n",
    "    for time in L_time:\n",
    "        temp_time = time.split()\n",
    "        temp_time_list = temp_time[0].split('-') + temp_time[1].split(':')\n",
    "        current_time = dt.datetime(year=int(temp_time_list[0]),\n",
    "                                    month=int(temp_time_list[1]),\n",
    "                                    day=int(temp_time_list[2]), \n",
    "                                    hour=int(temp_time_list[3]), \n",
    "                                    minute=int(temp_time_list[4])\n",
    "                                   )\n",
    "        time_difference = (current_time - base_time).total_seconds() / 60\n",
    "        L_time_minutes.append(time_difference)\n",
    "        \n",
    "    return L_time_minutes\n",
    "\n",
    "def calculate_amplitudes(L_time, L_pwl):\n",
    "    '''(list, list) -> dict\n",
    "    \n",
    "    Takes in a list of times L_time and a list of precision water levels L_pwl and calculates\n",
    "    a right-side amplitude approximation for every wave of the plot. Returns those amplitudes\n",
    "    as values paired with a key of the time of the peak for each amplitude in a dictionary.\n",
    "    '''\n",
    "    \n",
    "    start = 0\n",
    "    end = 0\n",
    "    amplitudes = {}\n",
    "    for i in range(1, len(L_pwl)):\n",
    "        if (len(L_pwl) - 1) == i:\n",
    "            break\n",
    "            \n",
    "        if L_pwl[i] < L_pwl[i+1] and L_pwl[i-1] >= L_pwl[i]:\n",
    "            start = L_pwl[i]\n",
    "        elif L_pwl[i] > L_pwl[i+1] and L_pwl[i-1] <= L_pwl[i]:\n",
    "            end = L_pwl[i]\n",
    "            peak = i\n",
    "            \n",
    "        if start and end:\n",
    "            amplitudes[L_time[peak]] = 100 * round(((abs(end-start)) / 2), 4)\n",
    "            start = 0\n",
    "            end = 0\n",
    "            \n",
    "    return amplitudes\n",
    "\n",
    "def find_start(time_list, pwl_list):\n",
    "    '''\n",
    "    (list, list) -> num\n",
    "\n",
    "    Takes in a list of times and percision water levels and returns an index on the \n",
    "    x axis(a time value) where the start of a tsunami event can be graphed.\n",
    "\n",
    "    '''\n",
    "    running_avg = 0\n",
    "    last_total = 0\n",
    "    for i in range(1, len(pwl_list)):\n",
    "        diff = abs(pwl_list[i] - pwl_list[i-1])\n",
    "        if i > 30:\n",
    "            if diff > running_avg*6.3:\n",
    "                return time_list[i]\n",
    "            else:\n",
    "                last_total = last_total + diff\n",
    "                running_avg = last_total/i\n",
    "        else: \n",
    "            last_total = last_total + diff\n",
    "            running_avg = last_total/i\n",
    "    return None\n",
    "\n",
    "def determine_max(sub_dict):\n",
    "    '''(dict) -> float\n",
    "    \n",
    "    Determines the high amplitude for a dictionary of amplitudes belongining to a dictionary\n",
    "    sub_dict. This function is only for use in the info_structure function. Returns a float\n",
    "    value of the highest amplitude.\n",
    "    \n",
    "    >>> determine_max({'amps': {1: 13, 2: 14, 3: 2}})\n",
    "    14.0\n",
    "    >>> determine_max({'amps': {1: 1.31, 2: 0.23, 3: 1.31}})\n",
    "    1.31\n",
    "    '''\n",
    "    amps = sub_dict['amps']\n",
    "    ctr = 0\n",
    "    for time in amps:\n",
    "        if amps[time] > ctr:\n",
    "            ctr = amps[time]\n",
    "    #if time <= sub_dict['start'] + 30:\n",
    "            \n",
    "    return ctr\n",
    "\n",
    "def find_distance(epilat, epilon, stations):\n",
    "    '''(float, float, list) -> list\n",
    "    \n",
    "    Takes in a latitude epilat and a longitude epilon for an origin point or epicenter\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    #In Kilometers\n",
    "    R = 6373.0\n",
    "\n",
    "    lat1 = math.radians(epilat)\n",
    "    lon1 = math.radians(epilon)\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    for station in stations:\n",
    "        lat2 = math.radians(station[0])\n",
    "        lon2 = math.radians(station[1])\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "\n",
    "        #Haversine formula\n",
    "        a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "        distance = R * c\n",
    "        distances.append(distance)\n",
    "    return distances\n",
    "\n",
    "def tsunami_speed(dictionaries):\n",
    "    color = ['bo--', 'go--', 'ro--']\n",
    "    c_i = 0\n",
    "    plt.figure()\n",
    "    for dictionary in dictionaries:\n",
    "        station_names = dictionary['station_names']\n",
    "        name = dictionary['name']\n",
    "        \n",
    "        velocities = []\n",
    "        for s in station_names:\n",
    "            velocities.append(dictionary[s]['max_amp'])\n",
    "            stations_lat_lon.append(dictionary[s]['lat_lon'])\n",
    "\n",
    "        distances = find_distance(epi_lat_lon[0], epi_lat_lon[1], stations_lat_lon)\n",
    "        plt.plot(distances, max_amps, color[c_i])\n",
    "        c_i = c_i + 1\n",
    "    plt.title('Max Wave Amplitude vs Distance')\n",
    "    plt.xlabel('Distance from Epicenter in Kilometers')\n",
    "    plt.ylabel('Max Amplitude in Centimeters')\n",
    "\n",
    "\n",
    "def info_structure(station_files, lat_lon_file, station_names, tsunami_name):\n",
    "    '''(list, str, list str) -> dict\n",
    "    \n",
    "    Complex function for creating a single container for all data associated to one tsunami.\n",
    "    Takes in a list of files for appropriate stations station_files, a string name for a \n",
    "    file coded with the latitudes and longitudes of relevant stations and epicenters lat_lon_file,\n",
    "    a list of the names of the stations as appearing in the lat_lon_file station_names, and lastly \n",
    "    a string of the tsunami name as appears in the lat_lon_file tsunami_name. Returns a complex \n",
    "    dict of all of this information. This resultant dict info structure is used in most plots.\n",
    "    '''\n",
    "    super_dict = {}\n",
    "    \n",
    "    latlon_dict = read_lat_lon(lat_lon_file)\n",
    "    \n",
    "    index = 0\n",
    "    for file in station_files:\n",
    "        sub_dict = {}\n",
    "        temp_times, temp_pwls = read_data(file)\n",
    "        sub_dict['long_times'] = temp_times\n",
    "        sub_dict['pwls'] = temp_pwls\n",
    "        sub_dict['times'] = data_point_time(temp_times)\n",
    "        sub_dict['amps'] = calculate_amplitudes(sub_dict['times'], temp_pwls)\n",
    "        sub_dict['start'] = find_start(sub_dict['times'], temp_pwls)\n",
    "        sub_dict['max_amp'] = determine_max(sub_dict)\n",
    "        sub_dict['lat_lon'] = latlon_dict[station_names[index]]\n",
    "        sub_dict['dist'] = find_distance(latlon_dict[tsunami_name][0], latlon_dict[tsunami_name][1], [sub_dict['lat_lon']])[0]\n",
    "        super_dict[station_names[index]] = sub_dict\n",
    "        index += 1\n",
    "        \n",
    "    super_dict['tsu_lat_lon'] = latlon_dict[tsunami_name]\n",
    "    super_dict['station_names'] = station_names\n",
    "    super_dict['name'] = tsunami_name\n",
    "    \n",
    "    return super_dict\n",
    "\n",
    "\n",
    "#Data Setup\n",
    "Japan_2011 = info_structure(['Japan(Omaezaki).txt', 'Japan(Honiara).txt', 'Japan(Westport_WA).txt'],\n",
    "                            'Lat_Lon.txt',\n",
    "                            ['Omaezaki', 'Honiara', 'Westport WA'],\n",
    "                            'Japan 2011'\n",
    "                           )\n",
    "\n",
    "Chile_2010 = info_structure(['Chile(Omaezaki).txt', 'Chile(Antofagasta_CL).txt', 'Chile(San_Felix_CL).txt'],\n",
    "                            'Lat_Lon.txt',\n",
    "                            ['Omaezaki', 'Antofagasta CL', 'San Felix CL'],\n",
    "                            'Chile 2010'\n",
    "                           )\n",
    "\n",
    "Solomon_2013 = info_structure(['Solomon_Islands(Honiara).txt', 'Solomon_Islands(Lata_Wharf_SB).txt', 'Solomon_Islands(Lautoka_FJ).txt'],\n",
    "                            'Lat_Lon.txt',\n",
    "                            ['Honiara', 'Lata Wharf SB', 'Lautoka FJ'],\n",
    "                            'Solomon Islands 2013'\n",
    "                           )\n",
    "\n",
    "tsunamis = [Japan_2011, Chile_2010, Solomon_2013]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explination of base functions\n",
    "\n",
    "There are a few basic functions that will be necessary to do certain calculations on the raw data. They are as explicitly seen above, but "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction of data\n",
    "\n",
    "IOC gathers tide guage data from monitoring stations around the world.  Gathering this data proved challenging.  Many of the stations were established years after the tsunami events we were examining, possibly in response to the disasters.  We also discovered stations with broken equipment, which would result in choppy or wildy innacurate measurements.  \n",
    "\n",
    "In the end, we found data from three stations per tsunami event.  This data comes in the form of a timestamp and a precision water level in meters.  Omaezaki and Honaira stations appear twice, as their readings proved reliable and multiple tsunamis showed for them.  \n",
    "\n",
    "We took five days of readings for the Japan and Chile events, and two days from the Solomon Islands event whose irregular behavior tapered out faster.  \n",
    "\n",
    "Below we have the raw data from the IOC plotted, with a blue line denoting when the event begins.  The precision water level is taken in meters, and the x-axis represents minutes after 12:00 AM the morning of the tsunami.  \n",
    "\n",
    "Note that it takes fewer days for the Solomon islands tsunami to subside.  Also note that the algorithm we wrote to determine the begining of the tsunami is sometimes thrown off by a sudden, smaller fluxuation in water level that preceeds a major fluxation such as what in the Honiara reading for Japan 2011.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variation(info_structure, station_name, color):\n",
    "    '''(list, str, str) -> None\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    plt.figure()\n",
    "    times = info_structure[station_name]['times']\n",
    "    pwls = info_structure[station_name]['pwls']\n",
    "    plt.plot(times, pwls, color + '--') \n",
    "    plt.axvline(find_start(times, pwls))\n",
    "    plt.title(f'Precision water level over time' + '(' + info_structure['name'] + ', ' + station_name + ')')\n",
    "    plt.xlabel('Minutes')\n",
    "    plt.ylabel('Percision Water Level(PWL)')\n",
    "    \n",
    "colors= ['b', 'g', 'r']\n",
    "    \n",
    "for i in range(3):\n",
    "    plot_variation(tsunamis[i], tsunamis[i]['station_names'][0], colors[i])\n",
    "for i in range(3):\n",
    "    plot_variation(tsunamis[i], tsunamis[i]['station_names'][1], colors[i])\n",
    "for i in range(3):\n",
    "    plot_variation(tsunamis[i], tsunamis[i]['station_names'][2], colors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of data\n",
    "\n",
    "Tsunami fluxuations appear as more of an alteration of normal tides, meaning that the tide still follows normal behaviour in spite of the tsunami. Later in the data we will see a graphic of the amplitude approximations to show the data without the fluctuation of tide.  What first surprised us about this data was that the tsunamis appear as violent jirations on an otherwise consistent pattern of high and low tides. A tsunami can make these normal tide fluxuations appear more pronounced, and a violent one can disrupt them entirely such as what is read on the Omaezaki plot for Japan 2011."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction of data\n",
    "\n",
    "The latitude and longitude of earthquakes (gathered by the USGS) as well as tide guage stations are plotted on this Mercator projection generated by Basemap. To get this data, we essentially had to record it into a text file manually before we read it into our program; we even wrote a specialized function for the task.  \n",
    "\n",
    "Earthquake epicenters appear as large dark colored diamonds, and associated stations appear as lighter versions of those same colors.  Note that the two stations are used multiple times, and are thus overlapped.  After experimenting with different types of projections and formats, we decided that a minmalist approach with just the coastlines and stations plotted was the most readable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def world_map_plot(info_structures):\n",
    "    '''(list) -> None\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0.05, 0.05, 0.9, 0.9])\n",
    "    m = Basemap(projection = 'merc', llcrnrlat = -80, urcrnrlat = 80, llcrnrlon = -180, urcrnrlon = 180, lat_ts = 20, resolution = 'c', lat_0=90, lon_0=-170)\n",
    "    #, llcrnrlat = -80, urcrnrlat = 80, llcrnrlon = -180, urcrnrlon = 180, lat_ts = 20, resolution = 'c'\n",
    "    \n",
    "    m.shadedrelief()\n",
    "    m.drawcoastlines()\n",
    "    m.drawmapboundary(fill_color = 'aqua')\n",
    "    #m.fillcontinents(color = 'mediumaquamarine')\n",
    "    \n",
    "    \n",
    "    colors1= ['dodgerblue', 'g', 'indianred']\n",
    "    colors2= ['midnightblue', 'darkgreen', 'darkred']\n",
    "    for tsunami in info_structures:\n",
    "        lats = []\n",
    "        lons = []\n",
    "        for station in tsunami['station_names']:\n",
    "            lons.append(tsunami[station]['lat_lon'][1])\n",
    "            lats.append(tsunami[station]['lat_lon'][0])\n",
    "            \n",
    "        x, y = m(lons, lats)\n",
    "        m.scatter(x, y, marker='H', color=colors1.pop())\n",
    "        \n",
    "        x2, y2 = m(tsunami['tsu_lat_lon'][1], tsunami['tsu_lat_lon'][0])\n",
    "        m.plot(x2, y2, marker='X', color=colors2.pop(), markersize=10)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "world_map_plot(tsunamis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction of data\n",
    "\n",
    "Amplitude of the wave readings are represented as scatter plots to illustrate how the wave subsides over time.  Amplitude is measured in centimeters, and and the timescale is once again measured in minutes after 12:00 AM the morning of the tsunami.  These amplitudes are calculated for each time stamp using the calculate_amplitudes() function, which takes in times and precision water levels and calculates a right-side amplitude approximation for each station.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_amplitude(info_structure, station, c):\n",
    "    '''(list, str, str) -> None\n",
    "    \n",
    "    '''\n",
    "\n",
    "    t1 = []\n",
    "    a1 = []\n",
    "\n",
    "    for time in info_structure[station]['amps']:\n",
    "        t1.append(time)\n",
    "        a1.append(info_structure[station]['amps'][time])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(t1, a1, color = c, s = 1)\n",
    "    plt.title('Amplitudes over time' + '(' + info_structure['name'] + ', ' + station + ')')\n",
    "    plt.xlabel('Minutes')\n",
    "    plt.ylabel('Amplitude in cm')\n",
    "    \n",
    "colors= ['b', 'g', 'r']\n",
    "    \n",
    "for n in range(3):\n",
    "    for i in range(3):\n",
    "        plot_amplitude(tsunamis[n], tsunamis[n]['station_names'][i], colors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction of data\n",
    "\n",
    "Max amplitudes are based off of full run of data, not first 30 minutes.  We made this choice because sometimes the beginning  of the tsunami as calculated would happen more than thirty minutes before the amplitude truly maxed out, so we tried to keep it as accurate as possible.  \n",
    "\n",
    "Here we've ploted the nine stations' distances from the triggering earthquake's epicenter vs the max amplitude in centimeters.  Results from this calculation are certainly not as straightforward as the previous plots, as you'll see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_amps_distances(dictionaries):\n",
    "    '''(list) -> None\n",
    "    \n",
    "    '''\n",
    "    color = ['bo--', 'go--', 'ro--']\n",
    "    c_i = 0\n",
    "    plt.figure()\n",
    "    for dictionary in dictionaries:\n",
    "        station_names = dictionary['station_names']\n",
    "        epi_lat_lon = dictionary['tsu_lat_lon']\n",
    "        name = dictionary['name']\n",
    "        \n",
    "        stations_lat_lon = []\n",
    "        max_amps = []\n",
    "        for s in station_names:\n",
    "            max_amps.append(dictionary[s]['max_amp'])\n",
    "            stations_lat_lon.append(dictionary[s]['lat_lon'])\n",
    "\n",
    "        distances = find_distance(epi_lat_lon[0], epi_lat_lon[1], stations_lat_lon)\n",
    "        plt.plot(distances, max_amps, color[c_i])\n",
    "        c_i = c_i + 1\n",
    "    plt.title('Max Wave Amplitude vs Distance')\n",
    "    plt.xlabel('Distance from Epicenter in Kilometers')\n",
    "    plt.ylabel('Max Amplitude in Centimeters')\n",
    "    \n",
    "plot_amps_distances(tsunamis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction of data\n",
    "\n",
    "Max amplitudes based off of full run of data, not first 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_amp_max_per_tsunami(info_structures, L_color_code):\n",
    "    '''(list, list) -> None\n",
    "    \n",
    "    '''\n",
    "   \n",
    "    plt.figure()\n",
    "    plt.xlabel('Tsunami')\n",
    "    plt.ylabel('Amplitude(cm)/Distance(km)')\n",
    "    ctr = 0\n",
    "    for tsunami in info_structures:\n",
    "        max_amps = []\n",
    "        max_amp = 0\n",
    "        for station in tsunami['station_names']:\n",
    "            max_temp = max_amp\n",
    "            max_amps.append(tsunami[station]['max_amp'])\n",
    "            max_amp = max(max_amps)\n",
    "            if max_amp != max_temp:\n",
    "                station_max = station\n",
    "        value = (max(max_amps)) / (tsunami[station_max]['dist'])\n",
    "        plt.bar(tsunami['name'], value, color = L_color_code[ctr])\n",
    "        ctr += 1\n",
    "    plt.show()\n",
    "    \n",
    "plot_amp_max_per_tsunami(tsunamis, ['b', 'g', 'r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
